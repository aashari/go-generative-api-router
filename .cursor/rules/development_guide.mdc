---
description: 
globs: 
alwaysApply: true
---
# Generative API Router Development Guide

This guide provides development workflow, best practices, and architectural guidance for the Generative API Router project.

> **Quick Start**: For setup and running instructions, see [Running and Testing Guide](mdc:running_and_testing.mdc)  
> **Codex Integration**: For AI-assisted development, see [Codex Guide](mdc:codex.mdc)

## Table of Contents

- [Project Structure](mdc:#project-structure) - Architecture and file organization
- [Terminal Command Rules](mdc:#terminal-command-rules) - Essential command-line best practices
- [Development Workflow](mdc:#development-workflow) - Core development cycle
- [Security Best Practices](mdc:#security-best-practices) - Sensitive data management
- [Git Workflow](mdc:#git-workflow) - PR creation and CI/CD monitoring
- [Release Process](mdc:#release-process) - Version management and releases
- [Deployment](mdc:#deployment) - AWS ECS production deployment
- [Maintenance](mdc:#maintenance) - Ongoing maintenance tasks
- [Common Pitfalls](mdc:#common-pitfalls--lessons-learned) - Lessons learned and troubleshooting

## Project Structure

### Core Application Code
- **`cmd/server/main.go`**: Main application entry point. Initializes and starts the HTTP server. ([cmd/server/main.go](mdc:generative-api-router/generative-api-router/generative-api-router/cmd/server/main.go))
- **`internal/app/app.go`**: Centralizes application configuration and dependencies (reduced to 64 lines after Phase 2 refactoring). ([internal/app/app.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/app/app.go))
- **`internal/proxy/proxy.go`**: Handles incoming requests, orchestrates vendor selection, request modification, and API communication. ([internal/proxy/proxy.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/proxy/proxy.go))
- **`internal/proxy/client.go`**: Manages communication with downstream vendor APIs. ([internal/proxy/client.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/proxy/client.go))
- **`internal/proxy/response_processor.go`**: Processes non-streaming responses from vendors. ([internal/proxy/response_processor.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/proxy/response_processor.go))
- **`internal/proxy/stream_processor.go`**: Handles streaming responses from vendors. ([internal/proxy/stream_processor.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/proxy/stream_processor.go))
- **`internal/selector/selector.go`**: Implements strategies for selecting vendors and models. ([internal/selector/selector.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/selector/selector.go))
- **`internal/validator/validator.go`**: Handles validation of incoming requests. It also extracts the original model name from the request. ([internal/validator/validator.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/validator/validator.go))
- **`internal/config/config.go`**: Loads and manages configuration from JSON files. ([internal/config/config.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/config/config.go))
- **`internal/config/validation.go`**: Validates credentials and model configurations. ([internal/config/validation.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/config/validation.go))
- **`internal/handlers/api_handlers.go`**: HTTP handlers for health, chat completions, and models endpoints. ([internal/handlers/api_handlers.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/handlers/api_handlers.go))
- **`internal/errors/errors.go`**: Standardized error types and JSON error responses. ([internal/errors/errors.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/errors/errors.go))
- **`internal/filter/utils.go`**: Utility functions for filtering credentials and models by vendor. ([internal/filter/utils.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/filter/utils.go))
- **`internal/monitoring/metrics.go`**: Performance profiling endpoints (pprof). ([internal/monitoring/metrics.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/monitoring/metrics.go))
- **`internal/router/routes.go`**: Centralized route setup with middleware integration. ([internal/router/routes.go](mdc:generative-api-router/generative-api-router/generative-api-router/internal/router/routes.go))

### Configuration Files
- **`configs/credentials.json`**: Stores API keys for different vendors (gitignored). ([configs/credentials.json.example](mdc:generative-api-router/generative-api-router/generative-api-router/configs/credentials.json.example))
- **`configs/models.json`**: Defines the available models and their vendors. ([configs/models.json](mdc:generative-api-router/generative-api-router/generative-api-router/configs/models.json))

### Deployment Files
- **`deployments/docker/Dockerfile`**: For building the Docker image. ([deployments/docker/Dockerfile](mdc:generative-api-router/generative-api-router/generative-api-router/deployments/docker/Dockerfile))
- **`deployments/docker/docker-compose.yml`**: For running the service with Docker Compose. ([deployments/docker/docker-compose.yml](mdc:generative-api-router/generative-api-router/generative-api-router/deployments/docker/docker-compose.yml))
- **`scripts/deploy.sh`**: AWS ECS deployment script (contains sensitive data, gitignored). ([scripts/deploy.sh](mdc:generative-api-router/generative-api-router/generative-api-router/scripts/deploy.sh))

### Development Tools
- **`Makefile`**: Build automation and common tasks. ([Makefile](mdc:generative-api-router/generative-api-router/generative-api-router/Makefile))
- **`scripts/`**: Helper scripts for deployment, testing, and setup
- **`examples/`**: Usage examples for cURL and various client languages
- **`docs/`**: Comprehensive documentation (API, development, user guides)
- **`.golangci.yml`**: Linter configuration for code quality

## Terminal Command Rules

### 🚨 CRITICAL CONSTRAINTS

When using terminal commands in development, follow these essential rules:

- **SINGLE-LINE ONLY**: No newline characters (`\n`) in commands
- **ALWAYS PIPE TO CAT**: End every command with `| cat` to avoid terminal issues
- **PROPER ESCAPING**: Use single quotes inside double quotes
- **NO LINE CONTINUATION**: Use semicolons (`;`) instead of backslashes (`\`)
- **COMMAND CHAINING**: Use `&&` for conditional execution, `;` for sequential execution

### ✅ Correct Terminal Patterns

```bash
# Git commits with multiple messages
git commit -m "feat: main commit message" -m "- First bullet point" -m "- Second bullet point" | cat

# Command chaining with proper error handling
make build && ./build/server > logs/server.log 2>&1 & echo "Server started" | cat

# Process checking and cleanup
pgrep -f "build/server$" | xargs -r kill -9 && echo "Server stopped" | cat

# Log monitoring with grep
tail -20 logs/server.log | grep -E "(error|Error|failed|Failed)" | cat

# AWS commands with proper formatting
aws --profile $AWS_PROFILE --region $AWS_REGION ecs describe-services --cluster $AWS_CLUSTER --services $AWS_SERVICE | cat
```

### ❌ Common Terminal Mistakes to Avoid

```bash
# These patterns will fail - avoid them
echo "multiline \
command"                         # Line continuation doesn't work

command_without_pipe             # Missing | cat can cause issues

curl http://example.com          # Should be: curl http://example.com | cat
```

## Development Workflow

> **Prerequisites**: Complete setup instructions are in [Running and Testing Guide](mdc:running_and_testing.mdc)

### Core Development Cycle

```bash
# 1. Make code changes
# 2. Run tests and linting
make test && make lint

# 3. Build and test locally  
make build && ./build/server > logs/server.log 2>&1 & sleep 3 && curl http://localhost:8082/health | cat

# 4. Check logs for issues
tail -20 logs/server.log | grep -E "(error|Error|failed|Failed)" | cat

# 5. Commit when ready (see Git Workflow section)
```

## Security Best Practices

### Sensitive Data Management
1. **ALWAYS check for sensitive data before committing**:
   ```bash
   # Check for AWS account IDs (12-digit numbers)
   grep -r -E '\b[0-9]{12}\b' --exclude-dir={.git,node_modules,vendor,.terraform,build} --exclude="*.log" .
   
   # Check for AWS access keys
   grep -r -E '(AKIA|ASIA|aws_access_key|aws_secret|AWS_ACCESS|AWS_SECRET)' --exclude-dir={.git,node_modules,vendor,.terraform,build} --exclude="*.log" .
   ```

2. **Deployment scripts often contain sensitive information**:
   - `scripts/deploy.sh` is gitignored as it contains AWS account IDs, VPC IDs, etc.
   - Never commit files with hardcoded credentials or infrastructure IDs

3. **Use environment variables or secret management for production**

## Git Workflow

### Creating Pull Requests
1. **Create a feature branch**:
   ```bash
   git checkout -b feat/your-feature-name
   ```

2. **Commit with detailed messages using multiple -m flags**:
   ```bash
   git commit -m "feat: main commit message" \
     -m "- First bullet point" \
     -m "- Second bullet point" \
     -m "" \
     -m "- Additional details"
   ```

3. **Push and create PR using GitHub CLI**:
   ```bash
   # Push branch
   git push -u origin feat/your-feature-name
   
   # Create PR with temporary file
   cat > pr-body-temp.md << 'EOF'
   # PR Title
   
   ## Summary
   ...
   EOF
   
   gh pr create --title "feat: your feature" --body-file pr-body-temp.md --base main
   rm pr-body-temp.md
   ```

### Monitoring GitHub Actions & CI/CD

**IMPORTANT**: After creating a PR, you MUST proactively monitor the GitHub Actions CI/CD pipeline and fix any issues before requesting review.

1. **Monitor PR Checks**:
   ```bash
   # Wait for CI to start (usually 30 seconds)
   sleep 30
   
   # Check PR CI status
   gh pr checks <PR_NUMBER>
   
   # Watch checks in real-time (refreshes every 10 seconds)
   watch -n 10 'gh pr checks <PR_NUMBER>'
   ```

2. **View Detailed CI Run**:
   ```bash
   # List recent workflow runs for your branch
   gh run list --branch <your-branch-name> --limit 5
   
   # View specific run details
   gh run view <RUN_ID>
   
   # View failed job logs
   gh run view <RUN_ID> --log-failed
   
   # View specific job logs
   gh run view --job=<JOB_ID>
   ```

3. **Common CI Monitoring Commands**:
   ```bash
   # Check PR status including CI checks
   gh pr view <PR_NUMBER>
   
   # Get PR checks in JSON format
   gh pr checks <PR_NUMBER> --json name,status,conclusion
   
   # Wait for checks to complete
   gh pr checks <PR_NUMBER> --watch
   ```

### Handling CI Failures

If CI checks fail, follow these steps:

1. **Identify the Issue**:
   ```bash
   # View failed logs
   gh run view <RUN_ID> --log-failed | grep -B 10 -A 10 "error\|Error\|failed\|Failed"
   
   # Check specific job that failed
   gh run view <RUN_ID> --job=<JOB_ID>
   ```

2. **Fix Issues Locally**:
   ```bash
   # Run CI checks locally before pushing
   make ci-check
   
   # Individual checks
   make format-check    # Code formatting
   make lint           # Linting
   make test-coverage  # Tests with coverage
   make build          # Build verification
   make security-scan  # Security scanning
   ```

3. **Push Fixes**:
   ```bash
   # After fixing issues
   git add .
   git commit -m "fix: address CI failures" \
     -m "- Fix formatting issues" \
     -m "- Resolve linting errors"
   git push
   
   # Monitor new CI run
   sleep 30 && gh pr checks <PR_NUMBER>
   ```

### Branch Protection Rules

This repository enforces the following rules:
- **No direct pushes to main**: All changes must go through pull requests
- **CI must pass**: PRs cannot be merged unless all CI checks are green
- **Up-to-date branch**: PRs must be up-to-date with main before merging

### PR Lifecycle Best Practices

1. **Before Creating PR**:
   - Run `make ci-check` locally
   - Ensure all tests pass
   - Check for sensitive data leaks

2. **After Creating PR**:
   - Monitor CI pipeline immediately
   - Fix any failures proactively
   - Don't wait for reviewers if CI is failing

3. **Example Complete Workflow**:
   ```bash
   # Create feature branch
   git checkout -b feat/awesome-feature
   
   # Make changes and test locally
   make ci-check
   
   # Commit and push
   git add .
   git commit -m "feat: add awesome feature" -m "- Implementation details"
   git push -u origin feat/awesome-feature
   
   # Create PR
   gh pr create --title "feat: awesome feature" --body "Add awesome feature with XYZ functionality"
   
   # Monitor CI (get PR number from create output)
   PR_NUM=$(gh pr list --head feat/awesome-feature --json number -q '.[0].number')
   echo "Monitoring PR #$PR_NUM"
   
   # Wait and check
   sleep 30
   gh pr checks $PR_NUM --watch
   
   # If failures occur
   gh run list --branch feat/awesome-feature --limit 1
   gh run view <RUN_ID> --log-failed
   
   # Fix and push
   # ... make fixes ...
   git add . && git commit -m "fix: address CI issues" && git push
   
   # Monitor again
   gh pr checks $PR_NUM --watch
   ```



### Core Architecture Principle

**Key Principle**: This service acts as a *transparent proxy* with a key modification. The router selects an actual vendor/model based on its internal logic (e.g., random selection, vendor filter). The `model` field in the request to the downstream vendor is overridden with this *actual selected model*. However, the `model` field in the final response back to the client is modified to reflect the *original model name the client sent in its initial request*. All other request and response data (headers, body structure excluding the model field, status code) from the vendor **must** be passed *exactly* to the client, and vice-versa. Changes must not interfere with this.

### Testing

> **Complete Testing Guide**: For comprehensive testing instructions including unit tests, manual testing, and debugging, see [Running and Testing Guide](mdc:running_and_testing.mdc)

## Release Process

### 🏷️ MANDATORY Release Workflow

Follow this systematic approach for creating releases:

#### 1. Pre-Commit Review Process

```bash
# 1. List modified files
git status --porcelain | grep '^ M' | cut -c 4- | cat

# 2. Review each file (replace <file> with actual path)
git diff --color <file> | cat

# 3. Check final logs for any issues
tail -10 logs/server.log | cat

# 4. Stage and commit with proper message
git add .
git commit -m "feat: describe changes based on diff review" -m "Detailed description if needed" | cat
```

#### 2. Version Management

```bash
# 1. Get current version and prepare for bump
CURRENT_VERSION=$(git describe --tags --abbrev=0 2>/dev/null || echo "v0.0.0") && echo "Current version: $CURRENT_VERSION" | cat

# 2. Review changes since last release
git log $(git describe --tags --abbrev=0 2>/dev/null || echo "HEAD~10")..HEAD --oneline | cat

# 3. Determine version bump type:
# - patch: Bug fixes, small improvements
# - minor: New features, non-breaking changes  
# - major: Breaking changes, API changes

# 4. Create new version tag (replace X.X.X with new version)
NEW_VERSION="v2.1.0"  # Example: increment based on changes
```

#### 3. Create Release Tag

```bash
# Create annotated tag with detailed release notes
git tag -a $NEW_VERSION -m "$NEW_VERSION: Brief release title" \
  -m "" \
  -m "FEATURES:" \
  -m "- New feature descriptions" \
  -m "" \
  -m "IMPROVEMENTS:" \
  -m "- Performance improvements" \
  -m "- Code quality enhancements" \
  -m "" \
  -m "FIXES:" \
  -m "- Bug fix descriptions" \
  -m "" \
  -m "BREAKING CHANGES:" \
  -m "- Any breaking changes (if major version)" | cat
```

#### 4. Push and Create GitHub Release

```bash
# 1. Push the tag to remote
git push origin $NEW_VERSION | cat

# 2. Create release notes file (temp file for GitHub release)
cat > temp-release-notes.md << 'EOF'
## ✨ What's New

### Features
- New feature descriptions with details
- Enhanced functionality explanations

### Improvements  
- Performance optimizations
- Code quality enhancements
- Better error handling

### Bug Fixes
- Fixed specific issues
- Resolved edge cases

### Technical Changes
- Updated dependencies
- Improved test coverage
- Enhanced documentation

## 🔧 Migration Guide

If there are breaking changes, provide migration instructions here.

## 📊 Impact

- Performance improvements
- Reduced memory usage
- Better reliability

## 🧪 Testing

- ✅ All tests passing
- ✅ Manual testing completed
- ✅ Performance verified
EOF

# 3. Create and publish GitHub release
gh release create $NEW_VERSION --title "🚀 Generative API Router $NEW_VERSION" --notes-file temp-release-notes.md | cat

# 4. Cleanup temp files
rm temp-release-notes.md && echo "Cleaned up release notes file" | cat
```

#### 5. Post-Release Verification

```bash
# 1. Verify release was created
gh release view $NEW_VERSION | cat

# 2. Check latest releases
gh release list --limit 3 | cat

# 3. Verify tag exists locally and remotely
git tag --sort=-version:refname | head -5 | cat
```

### ✅ Good Commit Message Examples

```bash
# Feature commits
git commit -m "feat: add health check monitoring" -m "Added comprehensive health check with dependency verification" | cat

# Documentation commits  
git commit -m "docs: update API documentation" -m "Added examples for streaming and tool calling endpoints" | cat

# Fix commits
git commit -m "fix: resolve proxy timeout issues" -m "Increased timeout values and added retry logic for vendor APIs" | cat

# Breaking change commits
git commit -m "feat!: remove metrics implementation" -m "BREAKING CHANGE: /metrics endpoint no longer available" | cat
```

### 📋 Pre-Release Checklist

- [ ] All modified files reviewed (`git diff --color <file>`)
- [ ] Logs checked for errors (`tail -20 logs/server.log`)
- [ ] Tests passing (`make test`)
- [ ] Linting clean (`make lint`)
- [ ] Security scan clean (`make security-scan`)
- [ ] Commit message follows conventional format
- [ ] Version bump appropriate for changes
- [ ] Release notes comprehensive and accurate

## Deployment

### AWS ECS Fargate Deployment
The project includes `scripts/deploy.sh` for AWS ECS deployment:

1. **Prerequisites**:
   - AWS CLI configured with appropriate profile
   - Docker installed and running
   - ECR repository access
   - Proper IAM permissions

2. **Deployment Script Requirements**:
   - The script expects Dockerfile in the root directory
   - If using the new structure, create a symlink: `ln -s deployments/docker/Dockerfile Dockerfile`
   - The script builds for ARM64 architecture

3. **Running Deployment**:
   ```bash
   ./scripts/deploy.sh
   ```

4. **Post-Deployment**:
   - Check CloudWatch logs for any issues
   - Verify health endpoint: `curl http://<load-balancer-url>/health`
   - Monitor ECS service for task health

## Maintenance

*   **Dependencies**: Run `go mod tidy` periodically to clean up dependencies. Key dependencies include:
    *   `github.com/stretchr/testify` v1.10.0 - Testing assertions
    *   `github.com/go-playground/validator/v10` v10.26.0 - Struct validation
*   **Configuration Updates**: API keys (`configs/credentials.json`) and model lists (`configs/models.json`) can be updated without code changes. Restart the server for changes to take effect.
*   **Logging**: Review logs in the `logs/` directory or console output. The server logs selected vendors/models for each request, the original requested model, and how the response model is being presented. Key log lines for debugging model handling include `VERBOSE_DEBUG: ProxyRequest - Original requested model:`, `VERBOSE_DEBUG: ProxyRequest - Selected Vendor:`, and `Processing response from actual model: ... will be presented as:`.
*   **Profiling**: The service includes pprof endpoints for performance profiling at `/debug/pprof/`.
*   **Code Quality**: 
    ```bash
    # Format code
    make format
    
    # Run linter
    make lint
    
    # Clean build artifacts and logs
    make clean
    make clean-logs
    ```

## Common Pitfalls & Lessons Learned

*   **Port Conflicts**: Always ensure port `:8082` (or the configured port) is free before starting the server. Use `sudo lsof -i :<port> | cat` and `sudo kill -9 <PID>`. For the local server, prefer `pgrep -f "^./server$" | xargs kill -9`.
*   **Server Startup Time**: *Always* add a short delay (e.g., `sleep 3`) after starting the server in the background before sending test `curl` requests. This prevents premature "Connection refused" errors.
*   **Curl Command Formatting**: Ensure JSON payloads in `curl -d` arguments are properly quoted and escaped, especially when using multi-line JSON. Single-line JSON with escaped quotes (e.g., `\'{\"key\": \"value\"}\'`) is often safer in scripts.
*   **Background Processes**: When starting the server with `&`, ensure it's managed correctly (e.g., `pgrep -f "^./server$" | xargs kill -9` to stop it specifically).
*   **Error Message Reliance**: Avoid relying on exact string matching for error messages. Use typed errors (`errors.Is()`) for more robust error handling.
*   **Project Structure Changes**: When reorganizing project structure:
    *   Update all file references in code
    *   Update Docker build contexts and COPY commands
    *   Update documentation paths
    *   Run verification scripts to ensure completeness
*   **Security Scans**: Always scan for sensitive data before committing:
    *   AWS account IDs, access keys, secrets
    *   Infrastructure IDs (VPCs, subnets, security groups)
    *   Any hardcoded credentials or tokens

---

Important: you can't read the `configs/credentials.json` using `read_file` tool, you can use `run_terminal_cmd` to `cat configs/credentials.json` instead