---
description: 
globs: 
alwaysApply: true
---
# Running and Testing Guide for Generative API Router

This guide provides step-by-step instructions for setting up, running, and testing the Generative API Router service.

> **Development Workflow**: For development best practices and Git workflow, see [Development Guide](mdc:development_guide.mdc)  
> **Codex Integration**: For AI-assisted development, see [Codex Guide](mdc:codex.mdc)

## üìö **Documentation Quick Reference**

### **Core Development Guides** (.cursor/rules/)
- **[Development Guide](mdc:development_guide.mdc)** - Complete workflow, Git practices, architecture principles
- **[Running & Testing Guide](mdc:running_and_testing.mdc)** - Setup, testing procedures, debugging techniques (this document)
- **[Codex Guide](mdc:codex.mdc)** - AI-assisted development workflow

### **User & API Documentation** (docs/)
- **[User Guide](mdc:../docs/user/README.md)** - *When integrating with the service* - API usage, configuration, client examples
- **[API Reference](mdc:../docs/api)** - *When implementing API calls* - OpenAPI specs, endpoint documentation
- **[Examples](mdc:../examples)** - *When writing client code* - Ready-to-use examples in Python, Node.js, Go

### **Development Documentation** (docs/development/)
- **[Development Guide](mdc:../docs/development/DEVELOPMENT.md)** - *When setting up locally* - Quick start, project structure, daily commands
- **[Contributing Guide](mdc:../docs/development/CONTRIBUTING.md)** - *When contributing code* - PR process, coding standards, review guidelines
- **[Testing Guide](mdc:../docs/development/TESTING.md)** - *When writing/running tests* - Test strategies, coverage, debugging
- **[Deployment Guide](mdc:../docs/development/DEPLOYMENT.md)** - *When managing AWS infrastructure* - xyz-aduh-genapi service, monitoring, troubleshooting

### **Project Overview**
- **[Main README](mdc:../README.md)** - *When getting project overview* - Features, quick start, architecture summary
- **[Documentation Index](mdc:../docs/README.md)** - *When navigating docs* - Complete documentation roadmap

---

## Table of Contents

- [Setup and Configuration](mdc:#setup-and-configuration) - Initial project setup
- [Running the Service](mdc:#running-the-service) - All methods to run the service
- [Running Tests](mdc:#running-tests) - Unit tests and test coverage
- [Log Monitoring & Debugging](mdc:#log-monitoring--debugging) - Essential debugging skills
- [Testing the Service](mdc:#testing-the-service) - Manual API testing
- [Troubleshooting](mdc:#troubleshooting) - Common issues and solutions
- [Quick Commands Reference](mdc:#quick-commands-reference) - Daily development commands

## Setup and Configuration

1. **Clone and Navigate**:
   ```bash
   git clone https://github.com/aashari/go-generative-api-router.git
   cd go-generative-api-router
   ```

2. **Initial Setup**:
   ```bash
   # Run the setup script to install dependencies and create config files
   make setup
   ```

3. **Configure Credentials**:
   - The setup script creates `configs/credentials.json` from the example file
   - Edit [configs/credentials.json](mdc:generative-api-router/generative-api-router/configs/credentials.json) with valid API keys (mostly you don't need to, because it might already exists with valid API keys already):
     ```json
     [
       {
         "platform": "openai",
         "type": "api-key",
         "value": "sk-your-openai-key"
       },
       {
         "platform": "gemini",
         "type": "api-key",
         "value": "your-gemini-key"
       }
     ]
     ```

4. **Configure Models**:
   - Edit [configs/models.json](mdc:generative-api-router/generative-api-router/configs/models.json) to specify which models you want to use (mostly you don't need to, because it might already exists with valid models already):
     ```json
     [
       {
         "vendor": "gemini",
         "model": "gemini-2.0-flash"
       },
       {
         "vendor": "openai",
         "model": "gpt-4o"
       }
     ]
     ```

## Running the Service

### Using Makefile (Recommended)

1. **Build and Run**:
   ```bash
   # Build and run the service
   make run
   
   # Run without building (using go run)
   make run-dev
   
   # Run with logging to file
   make run-with-logs
   ```

2. **Build Only**:
   ```bash
   make build
   # Binary will be in build/server
   ```

### Manual Execution

1. **Run the Built Binary**:
   ```bash
   ./build/server
   # OR for background execution:
   ./build/server > logs/server.log 2>&1 &
   ```
   - The server will start on port `:8082` by default.
   - Check logs in `logs/` directory or console output.
   - **Important**: Wait a few seconds (e.g., `sleep 3`) after starting the server before sending requests to avoid "Connection refused" errors.

### Using Docker

1. **Pre-deployment Checks**:
   ```bash
   # Check if port is already in use
   lsof -i :8082 | cat
   
   # Stop any existing containers
   make docker-stop
   ```

2. **Build and Run with Docker Compose**:
   ```bash
   # Using Makefile
   make docker-build
   make docker-run
   
   # OR manually
   docker-compose -f deployments/docker/docker-compose.yml up --build
   ```

3. **Run as a Background Service**:
   ```bash
   docker-compose -f deployments/docker/docker-compose.yml up -d
   
   # Stop the service
   make docker-stop
   ```

## Production Deployment

> **Deployment Guide**: For complete deployment instructions including AWS ECS setup, see [Development Guide - Deployment Section](mdc:development_guide.mdc#deployment)

## Running Tests

The project includes comprehensive test coverage added in Phase 2:

### Unit Tests

1. **Run All Tests**:
   ```bash
   make test
   # OR
   go test ./...
   ```

2. **Run Tests with Coverage**:
   ```bash
   make test-coverage
   # OR
   go test -cover ./...
   ```

3. **Run Specific Package Tests**:
   ```bash
   # Test handlers
   go test ./internal/handlers
   
   # Test with verbose output
   go test -v ./internal/errors
   ```

4. **Run Tests with Race Detection**:
   ```bash
   go test -race ./...
   ```

### Test Dependencies

The project uses:
- `github.com/stretchr/testify` v1.10.0 - For assertions and test suites
- `github.com/go-playground/validator/v10` v10.26.0 - For struct validation

Note: Some tests may skip if `configs/credentials.json` is not present, which is expected behavior.

## Log Monitoring & Debugging

### üìã Essential Log Monitoring (CRITICAL SKILL)

**Log Structure:**
The service generates structured JSON logs in the `logs/` directory:

```json
{
  "level": "info",
  "timestamp": "2025-01-27T10:30:45.123Z",
  "message": "Processing chat completion request",
  "request_id": "req_abc123",
  "component": "ProxyHandler",
  "vendor": "openai",
  "model": "gpt-4o"
}
```

**üîç Essential Log Commands:**

```bash
# Monitor in real-time (ALWAYS do this during testing)
tail -f logs/server.log

# Check recent activity
tail -50 logs/server.log | cat

# Find specific errors
grep -i "error" logs/server.log | tail -10 | cat

# Track specific request flow
grep "request_id.*abc123" logs/server.log | cat

# Component-specific logs
grep "ProxyHandler" logs/server.log | tail -5 | cat
grep "VendorSelector" logs/server.log | tail -5 | cat
```

**üïµÔ∏è Log Debugging Workflow:**

1. **Before Testing**: Clear understanding with `tail -10 logs/server.log | cat`
2. **During Testing**: Monitor with `tail -f logs/server.log` in separate terminal
3. **After Testing**: Review with `tail -20 logs/server.log | cat`
4. **Error Investigation**: Use `grep` to find error patterns

### üö® Emergency Commands

**Quick Recovery Commands:**

```bash
# Server crashed - quick recovery
pgrep -f "build/server$" | xargs -r kill -9 && make run && sleep 3 && curl http://localhost:8082/health | cat

# Check if API is responding
curl http://localhost:8082/health && echo "‚úÖ Local OK" | cat

# Check recent logs for errors
grep -i "error" logs/server.log | tail -5 | cat

# Process health check
ps aux | grep -E "(server|generative)" | grep -v grep | cat

# Memory usage check
free -h | cat
```

**üîß Process Management:**

```bash
# Check running processes
ps aux | grep -E "(server|go)" | grep -v grep | cat

# Find and kill server processes
pgrep -f "build/server$" | xargs -r kill -9 && echo "Server stopped" | cat

# Check port usage
lsof -i :8082 | cat

# Start server in background with logging
./build/server > logs/server.log 2>&1 & echo "Server started with PID $!" | cat
```

### üîç Debugging Checklist

**üö® When something is broken:**

1. **Server Health**: `curl -v http://localhost:8082/health | cat`
2. **Check Logs**: `tail -20 logs/server.log | cat`
3. **Process Status**: `ps aux | grep server | grep -v grep | cat`
4. **Port Conflicts**: `lsof -i :8082 | cat`
5. **Recent Errors**: `grep -i "error" logs/server.log | tail -10 | cat`
6. **Configuration**: `cat configs/credentials.json | jq | cat` (check if valid JSON)

**üîß Common Issues & Solutions:**

| Issue | Symptoms | Solution |
|-------|----------|----------|
| Server Crash | `curl` connection refused | `pgrep -f "build/server$" \| xargs -r kill -9 && make run` |
| Port Conflict | "address already in use" | `lsof -i :8082 \| grep LISTEN \| awk '{print $2}' \| xargs -r kill -9` |
| Config Error | Server won't start | `cat configs/credentials.json \| jq` to validate JSON |
| Memory Issues | Slow responses | `free -h && ps aux --sort=-%mem \| head -10` |

## Testing the Service

### Testing Best Practices

1. **Always Clean Environment First**:
   ```bash
   # Kill any process on port 8082
   sudo lsof -i :8082 | grep LISTEN | awk '{print $2}' | xargs -r sudo kill -9
   
   # Or safer for specific server
   pgrep -f "build/server$" | xargs -r kill -9
   ```

2. **Wait for Service Readiness**:
   ```bash
   # Start service
   make run &
   
   # ALWAYS wait before testing
   sleep 3
   
   # Verify it's ready
   curl -s http://localhost:8082/health | cat || echo "Service not ready yet"
   ```

### Using Example Scripts

Example scripts are provided in the `examples/` directory:

```bash
# Basic usage examples
./examples/curl/basic.sh

# Streaming examples
./examples/curl/streaming.sh

# Tool calling examples
./examples/curl/tools.sh
```

### Basic Tests

1. **Health Check**:
   ```bash
   curl -X GET http://localhost:8082/health | cat
   ```
   - Expected: `OK` with status code 200

2. **List Available Models**:
   ```bash
   curl -X GET http://localhost:8082/v1/models | jq | cat
   ```
   - Lists all configured models in OpenAI-compatible format

3. **Basic Chat Completion**:
   ```bash
   curl -X POST http://localhost:8082/v1/chat/completions \
     -H "Content-Type: application/json" \
     -d '{"model": "any-model-name-you-like", "messages": [{"role": "user", "content": "Hello"}]}' | jq | cat
   ```
   - Verify that the response includes:
     - A proper `"id"` field with `"chatcmpl-"` prefix
     - Content in the expected format
     - The `"model"` field in the response should match the `"model"` field sent in the request (e.g., `"any-model-name-you-like"`).
   - **Log Check**: Verify server logs (e.g., `grep "VERBOSE_DEBUG: ProxyRequest" logs/server.log | tail -n 1`) show the requested model and the actual model selected by the router. Example:
     `VERBOSE_DEBUG: ProxyRequest - Original requested model: 'any-model-name-you-like', will route to: 'actual-selected-model'`
   - Also check for `Processing response from actual model:` log line.



### Advanced Testing

1. **Streaming Response Test**:
   ```bash
   curl -X POST http://localhost:8082/v1/chat/completions \\
     -H "Content-Type: application/json" \\
     -d \'{\"model\": \"my-streaming-test-model\", \"messages\": [{\"role\": \"user\", \"content\": \"Count from 1 to 3\"}], \"stream\": true}\' | cat
   ```
   - Verify that responses come as Server-Sent Events with `data:` prefix.
   - Check each chunk has a consistent `\"id\"` field.
   - **Crucially, verify each data chunk's `\"model\"` field matches the requested model (e.g., `\"my-streaming-test-model\"`).**
   - Confirm the stream ends with `data: [DONE]`.
   - **Log Check**: Verify server logs for entries like `Initiating streaming from vendor ... will be presented as my-streaming-test-model`.

2. **Tool Calling Test**:
   ```bash
   curl -X POST http://localhost:8082/v1/chat/completions \\
     -H "Content-Type: application/json" \\
     -d \'{\"model\": \"tool-test-model\", \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in Boston?\"}], \"tools\": [{\"type\": \"function\", \"function\": {\"name\": \"get_weather\", \"description\": \"Get weather information for a location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"City name\"}}, \"required\": [\"location\"]}}}], \"tool_choice\": \"auto\"}\' | jq | cat
   ```
   - Verify that tool calls include a proper `\"id\"` field with `\"call_\"` prefix.
   - Check tool call arguments and function name are correctly formatted.
   - Ensure the `\"model\"` field in the response matches `\"tool-test-model\"`.
   - **Log Check**: Verify server logs for original vs. actual model routing.

3. **Vendor-Specific Testing**:
   ```bash
   curl -X POST \"http://localhost:8082/v1/chat/completions?vendor=openai\" \\
     -H \"Content-Type: application/json\" \\
     -d \'{\"model\": \"specific-vendor-openai-model\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello from OpenAI test\"}]}\' | jq | cat
   ```
   ```bash
   curl -X POST \"http://localhost:8082/v1/chat/completions?vendor=gemini\" \\
     -H \"Content-Type: application/json\" \\
     -d \'{\"model\": \"specific-vendor-gemini-model\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello from Gemini test\"}]}\' | jq | cat
   ```
   - Verify that each vendor properly responds.
   - Ensure the `\"model\"` field in each response matches what was sent in the request for that vendor.
   - **Log Check**: Verify server logs for vendor-specific routing and model name handling.

4. **Error Response Testing**:
   ```bash
   # Test missing messages field (validation error)
   curl -X POST http://localhost:8082/v1/chat/completions \\
     -H "Content-Type: application/json" \\
     -d \'{\"model\": \"test-model\"}\' | jq | cat
   ```
   - Expected: Standardized error response with:
     - `error.type` - Error category (e.g., "invalid_request_error")
     - `error.message` - Human-readable error message
     - HTTP status code 400

   ```bash
   # Test with invalid JSON
   curl -X POST http://localhost:8082/v1/chat/completions \\
     -H "Content-Type: application/json" \\
     -d \'invalid json\' | jq | cat
   ```
   - Expected: JSON parsing error with proper error structure

## Troubleshooting

1. **Port Conflicts**:
   - Check if port 8082 is already in use:
     ```bash
     lsof -i :8082 | cat
     ```
   - Kill conflicting processes:
     ```bash
     kill -9 <PID> # Use with caution
     ```

2. **Connection Refused Errors**:
   - Ensure the server has fully started before sending requests.
   - **Wait a few seconds** (e.g., `sleep 3`) after starting the server.

3. **Invalid API Key Errors**:
   - Verify your API keys in `configs/credentials.json` are valid and current.
   - Check vendor-specific error messages in the response.

4. **Request Validation Errors**:
   - Ensure your request has the required `\"messages\"` field.
   - Check that tools and tool_choice are properly formatted.
   - The service now provides detailed validation error messages in a standardized format.

5. **Server Crashes**:
   - Check the server logs for error messages (e.g., `tail logs/server.log`).
   - Ensure `configs/credentials.json` and `configs/models.json` are valid JSON files.

6. **Deployment Issues**:
   - **ECR Login Failed**: Ensure AWS CLI is configured with correct profile
   - **Docker Build Failed**: Check if Dockerfile exists in expected location
   - **ECS Task Failed to Start**: Check CloudWatch logs for the task
   - **Load Balancer Not Responding**: Wait a few minutes for tasks to become healthy

## Stopping the Service

### Using Makefile:
```bash
# Stop Docker containers
make docker-stop

# Clean build artifacts and logs
make clean
make clean-logs
```

### Manually:
```bash
# If running in foreground, press Ctrl+C
# If running in background (more specific to avoid killing other 'server' processes):
pgrep -f "build/server$" | xargs kill -9 || echo "Server not found or already stopped"
# Alternatively:
# pkill -f "build/server$"
```

### Docker:
```bash
docker-compose -f deployments/docker/docker-compose.yml down
```

## Quick Commands Reference

### üöÄ Daily Development Commands

```bash
# Complete development session startup
make build && ./build/server > logs/server.log 2>&1 & sleep 3 && curl http://localhost:8082/health | cat

# Full API test cycle
curl http://localhost:8082/health && echo "‚úÖ Health OK" && curl -X POST http://localhost:8082/v1/chat/completions -H "Content-Type: application/json" -d '{"model":"test","messages":[{"role":"user","content":"Hello"}]}' | jq '.model' && echo "‚úÖ Chat OK" | cat

# Quick health check all endpoints
echo "Health:" && curl -s http://localhost:8082/health | head -c 20 && echo "..." && echo "Models:" && curl -s http://localhost:8082/v1/models | jq '.data | length' && echo "models available" | cat

# Log monitoring with error filtering
tail -f logs/server.log | grep -E "(error|Error|failed|Failed|panic)" --color=always

# Process and memory status
echo "=== PROCESS STATUS ===" && ps aux | grep -E "(server|go)" | grep -v grep && echo "=== MEMORY USAGE ===" && free -h | cat
```

### üîß Maintenance Commands

```bash
# Clean restart
pgrep -f "build/server$" | xargs -r kill -9 && make clean && make build && ./build/server > logs/server.log 2>&1 & sleep 3 && curl http://localhost:8082/health | cat

# Log file management
ls -lh logs/ && echo "=== Recent Errors ===" && grep -i "error" logs/server.log | tail -3 | cat

# Configuration validation
echo "=== Credentials Check ===" && cat configs/credentials.json | jq length && echo "credentials configured" && echo "=== Models Check ===" && cat configs/models.json | jq length && echo "models configured" | cat

# Performance check
echo "=== Response Time Test ===" && time curl -s http://localhost:8082/health > /dev/null && echo "=== Memory Usage ===" && ps aux --sort=-%mem | head -5 | cat
```

### üß™ Testing Commands

```bash
# Comprehensive API test
echo "=== HEALTH TEST ===" && curl http://localhost:8082/health && echo "" && echo "=== MODELS TEST ===" && curl -s http://localhost:8082/v1/models | jq '.data[0].id' && echo "=== CHAT TEST ===" && curl -s -X POST http://localhost:8082/v1/chat/completions -H "Content-Type: application/json" -d '{"model":"test","messages":[{"role":"user","content":"Hi"}],"max_tokens":10}' | jq '.model' | cat

# Streaming test
curl -X POST http://localhost:8082/v1/chat/completions -H "Content-Type: application/json" -d '{"model":"stream-test","messages":[{"role":"user","content":"Count 1 to 3"}],"stream":true,"max_tokens":20}' | head -10 | cat

# Error handling test
echo "=== VALIDATION ERROR TEST ===" && curl -X POST http://localhost:8082/v1/chat/completions -H "Content-Type: application/json" -d '{"model":"test"}' | jq '.error.message' | cat
```

## Additional Resources

- See `docs/development/` for development guides
- Check `examples/clients/` for client library examples in Go, Node.js, and Python
- Run `make help` to see all available Makefile targets
- Review `scripts/verify-structure.sh` to validate project structure
